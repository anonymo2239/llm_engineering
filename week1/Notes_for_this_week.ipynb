{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "092cbdfb-53ac-4d3a-a18a-4f944af26b30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![image.png](image01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8715e438-0e5f-4d24-bedc-2c133ee256d6",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ”  **LLM (Large Language Model)** nedir?\n",
    "\n",
    "**Ã‡ok bÃ¼yÃ¼k miktarda metin verisiyle eÄŸitilmiÅŸ yapay zeka modelleridir.**\n",
    "DoÄŸal dil Ã¼retme, anlama, Ã§eviri, Ã¶zetleme gibi gÃ¶revleri yerine getirir.\n",
    "ğŸ‘‰ *(Ã–rnek: GPT-4, Claude, LLaMA, Mistral)*\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Models (Modeller)\n",
    "\n",
    "* **Open-Source:** Kaynak kodu aÃ§Ä±k modeller.\n",
    "  ğŸ‘‰ *(Ã–rnek: LLaMA 2, Mistral, Falcon)*\n",
    "* **Closed Source:** Kaynak kodu kapalÄ±, sadece API ile eriÅŸilebilen modeller.\n",
    "  ğŸ‘‰ *(Ã–rnek: GPT-4, Claude)*\n",
    "* **Multi-modal:** Metin + GÃ¶rsel + Ses gibi farklÄ± veri tÃ¼rlerini aynÄ± anda iÅŸleyebilen modeller.\n",
    "  ğŸ‘‰ *(Ã–rnek: GPT-4o, Gemini, Claude 3.5 Sonnet)*\n",
    "* **Architecture:** Modelin katman yapÄ±sÄ±, dikkat mekanizmalarÄ±, transformer yapÄ±sÄ± gibi iÃ§ tasarÄ±mÄ±.\n",
    "  ğŸ‘‰ *(Ã–rnek: Decoder-only, Encoder-decoder transformer)*\n",
    "* **Selecting:** Uygun modeli seÃ§me sÃ¼reci; kullanÄ±m senaryosuna gÃ¶re doÄŸru LLMâ€™i belirleme.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ Tools (AraÃ§lar)\n",
    "\n",
    "* **HuggingFace:** Model paylaÅŸÄ±mÄ±, eÄŸitimi ve Ã§alÄ±ÅŸtÄ±rmasÄ± iÃ§in popÃ¼ler bir platform.\n",
    "  ğŸ‘‰ *(transformers, datasets gibi paketleri vardÄ±r)*\n",
    "* **LangChain:** LLM'leri zincirleme iÅŸlemler ve dÄ±ÅŸ kaynaklarla (veritabanÄ±, API) baÄŸlama kÃ¼tÃ¼phanesi.\n",
    "  ğŸ‘‰ *(Ã–rnek: veritabanÄ±ndan bilgi al, LLMâ€™e gÃ¶nder, sonuÃ§ Ã¼ret)*\n",
    "* **Gradio:** Modeller iÃ§in hÄ±zlÄ±ca web arayÃ¼zÃ¼ oluÅŸturmayÄ± saÄŸlayan araÃ§.\n",
    "* **Weights & Biases:** EÄŸitim sÃ¼recini gÃ¶rselleÅŸtirme ve izleme aracÄ± (ML ops iÃ§in).\n",
    "* **Modal:** Sunucusuz (serverless) LLM uygulamalarÄ± daÄŸÄ±tÄ±mÄ± iÃ§in platform.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Techniques (Teknikler)\n",
    "\n",
    "* **APIs:** Modellerle REST API Ã¼zerinden iletiÅŸim kurma yÃ¶ntemi.\n",
    "  ğŸ‘‰ *(Ã–rnek: OpenAI API kullanarak cevap alma)*\n",
    "* **Multi-shot prompting:** LLM'e birden fazla Ã¶rnek vererek daha doÄŸru cevap almayÄ± hedefleme.\n",
    "  ğŸ‘‰ *(Ã–rnek: 3 soru-cevap Ã¶rneÄŸi verip 4. cevabÄ± istemek)*\n",
    "* **RAG (Retrieval-Augmented Generation):** LLM'e dÄ±ÅŸ kaynaktan bilgi getirip, o bilgiyle cevap Ã¼rettirme.\n",
    "  ğŸ‘‰ *(Ã–rnek: Belgeleri tarayÄ±p onlardan Ã¶zet Ã¼retme)*\n",
    "* **Fine-tuning:** Modelin belirli bir gÃ¶rev veya veriyle yeniden eÄŸitilmesi.\n",
    "  ğŸ‘‰ *(Ã–rnek: Bir mÃ¼ÅŸteri hizmetleri chatbot'u iÃ§in GPT'yi ince ayarlamak)*\n",
    "* **Agentization:** LLM'in kendi kararlarÄ±nÄ± verip adÄ±m adÄ±m iÅŸlem yapabilen \"ajan\" gibi Ã§alÄ±ÅŸmasÄ±.\n",
    "  ğŸ‘‰ *(Ã–rnek: Bir gÃ¶revi Ã§Ã¶zÃ¼me ulaÅŸtÄ±rmak iÃ§in araÃ§ Ã§aÄŸÄ±rma, plan yapma)*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c2da3c-5323-4dee-b346-d1972e67be16",
   "metadata": {},
   "source": [
    "![image.png](image02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348d91d-25d8-488c-bb11-ad883c4198bd",
   "metadata": {},
   "source": [
    "\n",
    "1. **Chat interfaces (Sohbet ArayÃ¼zleri):**\n",
    "\n",
    "   * Ã–rnek: ChatGPT gibi platformlar\n",
    "   * KullanÄ±cÄ±larÄ±n doÄŸrudan sohbet ederek modeli kullanmalarÄ±nÄ± saÄŸlar.\n",
    "\n",
    "2. **Cloud APIs (Bulut APIâ€™leri):**\n",
    "\n",
    "   * LLM APIâ€™leri Ã¼zerinden\n",
    "   * LangChain gibi frameworkâ€™lerle entegre edilir.\n",
    "   * YÃ¶netilen AI hizmetleri:\n",
    "\n",
    "     * Amazon Bedrock\n",
    "     * Google Vertex\n",
    "     * Azure ML\n",
    "\n",
    "3. **Direct inference (DoÄŸrudan Ã§Ä±karÄ±m):**\n",
    "\n",
    "   * HuggingFace Transformers kÃ¼tÃ¼phanesi ile\n",
    "   * Ollama gibi araÃ§larla yerel Ã§alÄ±ÅŸtÄ±rma yapÄ±labilir.\n",
    "\n",
    "---\n",
    "### **YÃ¶netilen AI hizmetleri:**\n",
    "\n",
    "Bunlar, bÃ¼yÃ¼k bulut saÄŸlayÄ±cÄ±larÄ±nÄ±n sunduÄŸu hazÄ±r altyapÄ±lardÄ±r. Model eÄŸitme, Ã§alÄ±ÅŸtÄ±rma ve Ã¶lÃ§ekleme iÅŸlemlerini senin yerine yaparlar.\n",
    "\n",
    "* **Amazon Bedrock, Google Vertex AI, Azure ML** gibi platformlar buna Ã¶rnektir.\n",
    "* Kendi donanÄ±mÄ±n olmadan bÃ¼yÃ¼k dil modellerini kullanabilirsin.\n",
    "\n",
    "### **Ollama:**\n",
    "\n",
    "Ollama, dil modellerini **kendi bilgisayarÄ±nda (lokal)** Ã§alÄ±ÅŸtÄ±rmanÄ± saÄŸlayan bir araÃ§tÄ±r.\n",
    "\n",
    "* Ä°nternete gerek kalmadan, Ã¶rneÄŸin LLaMA gibi modelleri PCâ€™de hÄ±zlÄ±ca Ã§alÄ±ÅŸtÄ±rabilirsin.\n",
    "* GeliÅŸtiriciler iÃ§in hafif ve kolaydÄ±r.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e295c1f-80ac-4f5d-9d77-bf104422cbd1",
   "metadata": {},
   "source": [
    "# Frontier AI Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce83136-58b1-44ab-8a1e-0152ece7df39",
   "metadata": {},
   "source": [
    "![image.png](image03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3596da2-678e-4dde-86d1-117e326e4be8",
   "metadata": {},
   "source": [
    "![image.png](image04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791bf26-a222-47e8-9989-487151ccdd49",
   "metadata": {},
   "source": [
    "Frontier LLMâ€™ler artÄ±k bilgi sentezi, yazÄ± Ã¼retimi ve kodlama gibi konularda insan dÃ¼zeyine Ã§ok yaklaÅŸmÄ±ÅŸ durumda.\n",
    "\n",
    "Bu yÃ¼zden insanlar artÄ±k Stack Overflow gibi sitelere deÄŸil, bu modellere baÅŸvuruyor.\n",
    "\n",
    "Yani bu modeller, hem bilgi kaynaklarÄ±nÄ± deÄŸiÅŸtiriyor hem de Ã§alÄ±ÅŸma alÄ±ÅŸkanlÄ±klarÄ±nÄ± kÃ¶kten etkiliyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27309d-61b3-45f3-b4a1-fabe7fdd5c14",
   "metadata": {},
   "source": [
    "![image.png](image05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3b783-299c-4c97-b386-46316f509b3c",
   "metadata": {},
   "source": [
    "## Neden Frontier Modeller basit sorularda yanlÄ±ÅŸ yapar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378a5c5-da96-474a-8bfa-719681330883",
   "metadata": {},
   "source": [
    "GerÃ§ek ÅŸu ki, bu bilginin LLM'e gÃ¶nderilme ÅŸekliyle ve tokenizasyon stratejisi ilgili. LLM harfler veya kelimeler nedir bilmez. Token'larÄ± alÄ±rlar ve bundan dolayÄ± Ã§oÄŸu zaman bÃ¼yÃ¼k matematiksel iÅŸlemleri yapamazlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec6ce3-4b52-4bae-a273-db53efacf360",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "* TÃ¼m 6 ileri dÃ¼zey LLM modeli ÅŸaÅŸÄ±rtÄ±cÄ± derecede iyi.  \n",
    "Ã–zellikle bilgiyi sentezleme ve ayrÄ±ntÄ±lÄ± cevaplar Ã¼retme konusunda Ã§ok baÅŸarÄ±lÄ±lar.\n",
    "\n",
    "* Claude (Anthropic'in LLM'si), pratikte en Ã§ok tercih edilen model.  \n",
    "Ã‡Ã¼nkÃ¼ daha esprili, gÃ¼venliÄŸe daha Ã§ok Ã¶nem veriyor ve daha Ã¶zlÃ¼ yanÄ±tlar veriyor.\n",
    "\n",
    "* Modellerin yetenekleri birbirine yaklaÅŸtÄ±kÃ§a, fiyat fark yaratabilir.  \n",
    "Yeni geliÅŸtirmeler, daha ucuz modellere odaklanÄ±yor.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40b6396e-7981-4892-99bf-cadcd256fbd5",
   "metadata": {},
   "source": [
    "![image.png](image06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b0caf-bc99-4694-a9f7-7f4c1c1bb633",
   "metadata": {},
   "source": [
    "Google'daki Ã§alÄ±ÅŸanlar \"Attention is All You need\" makalesini yayÄ±mladÄ± ve ilk kez transformer modeller burada bahsedildi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6304cf5-7be7-48b2-b2ab-f72774225982",
   "metadata": {},
   "source": [
    "## LLM'in parametreleri:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237a6f9-f452-4ee4-bebf-a6e9e7b08b4c",
   "metadata": {},
   "source": [
    "LLM'lerde parametre sayÄ±sÄ±, modelin **Ã¶ÄŸrenilebilir aÄŸÄ±rlÄ±k ve bias deÄŸerlerinin** toplam sayÄ±sÄ±nÄ± ifade eder.\n",
    "\n",
    "**Parametreler nelerdir?**\n",
    "- **AÄŸÄ±rlÄ±klar (weights)**: Katmanlar arasÄ±ndaki baÄŸlantÄ±larÄ±n gÃ¼cÃ¼nÃ¼ belirleyen deÄŸerler\n",
    "- **Bias deÄŸerleri**: Her nÃ¶ronun aktivasyon eÅŸiÄŸini ayarlayan deÄŸerler\n",
    "- **Embedding matrisleri**: Kelimeleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼ren tablolar\n",
    "- **Attention mekanizmasÄ± aÄŸÄ±rlÄ±klarÄ±**: Transformer'larda hangi kelimelere odaklanacaÄŸÄ±nÄ± belirleyen deÄŸerler\n",
    "\n",
    "**Neden Ã¶nemli?**\n",
    "- **Model kapasitesi**: Daha fazla parametre genellikle daha karmaÅŸÄ±k kalÄ±plarÄ± Ã¶ÄŸrenebilme yeteneÄŸi demek\n",
    "- **Hesaplama maliyeti**: Parametre sayÄ±sÄ± arttÄ±kÃ§a eÄŸitim ve Ã§alÄ±ÅŸtÄ±rma maliyeti artar\n",
    "- **Bellek gereksinimi**: Her parametre bellekte yer kaplar\n",
    "\n",
    "**Ã–rnekler:**\n",
    "- GPT-3: ~175 milyar parametre\n",
    "- GPT-4: Tam sayÄ± aÃ§Ä±klanmadÄ± ama trilyon civarÄ±nda tahmin ediliyor\n",
    "- BERT Base: ~110 milyon parametre\n",
    "\n",
    "Yani kÄ±saca, parametre sayÄ±sÄ± modelin \"beyinindeki sinaps sayÄ±sÄ±\" gibi dÃ¼ÅŸÃ¼nÃ¼lebilir - ne kadar Ã§ok parametre, o kadar karmaÅŸÄ±k dÃ¼ÅŸÃ¼nme yeteneÄŸi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191594a-fb1f-46cb-a0c0-18d7b2ec33df",
   "metadata": {},
   "source": [
    "![image.png](image07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a38c9f2-6d34-4add-b063-f1a3f3b9d80c",
   "metadata": {},
   "source": [
    "![image.png](image08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f74187-e915-4942-b26d-b7e7fc818fee",
   "metadata": {},
   "source": [
    "\n",
    "**Token nedir?**  \n",
    "Token, LLM'lerin metni iÅŸlerken kullandÄ±ÄŸÄ± en kÃ¼Ã§Ã¼k anlamlÄ± birimdir. Kelimeden daha kÃ¼Ã§Ã¼k, karakterden daha bÃ¼yÃ¼k parÃ§alardÄ±r.\n",
    "\n",
    "**GÃ¶rseldekilerin aÃ§Ä±klamasÄ±:**\n",
    "\n",
    "**1. Karakter seviyesi (sol):**\n",
    "- Her harf ayrÄ± ayrÄ± iÅŸlenir\n",
    "- KÃ¼Ã§Ã¼k kelime daÄŸarcÄ±ÄŸÄ± ama Ã§ok fazla adÄ±m gerekir\n",
    "- \"Merhaba\" iÃ§in 7 adÄ±m (m-e-r-h-a-b-a)\n",
    "\n",
    "**2. Kelime seviyesi (orta):**\n",
    "- Her kelime bir birim olarak iÅŸlenir\n",
    "- Ã–ÄŸrenmesi kolay ama nadir kelimeler sorun yaratÄ±r\n",
    "- Kelime daÄŸarcÄ±ÄŸÄ± Ã§ok bÃ¼yÃ¼k olur\n",
    "\n",
    "**3. Token seviyesi (saÄŸ) - En ideal Ã§Ã¶zÃ¼m:**\n",
    "- Kelimelerin parÃ§alarÄ±na bÃ¶lÃ¼nÃ¼r\n",
    "- Hem yÃ¶netilebilir kelime daÄŸarcÄ±ÄŸÄ± hem de verimli iÅŸleme\n",
    "- Ek'leri, kÃ¶k'leri ayrÄ± ayrÄ± anlayabilir\n",
    "\n",
    "**Ã–rnekler:**\n",
    "- \"oyuncu\" â†’ [\"oyun\", \"cu\"]\n",
    "- \"koÅŸuyorum\" â†’ [\"koÅŸ\", \"uyor\", \"um\"]\n",
    "- \"AI\" â†’ [\"A\", \"I\"] (kÄ±sa olduÄŸu iÃ§in bÃ¶lÃ¼nmez)\n",
    "\n",
    "**Neden Ã¶nemli?**\n",
    "- FarklÄ± dillerdeki ekleri anlayabilir\n",
    "- Yeni kelimeler gÃ¶rse bile kÃ¶k ve eklerden anlam Ã§Ä±karabilir\n",
    "- Bellek kullanÄ±mÄ± optimize edilir\n",
    "\n",
    "Token'lar sayesinde LLM'ler hem verimli hem de esnek bir ÅŸekilde dil iÅŸleyebilirler!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4910791-e9a4-42d7-b550-799009e6551d",
   "metadata": {},
   "source": [
    "![image.png](image09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df01ec-2a87-43ae-be84-763e6dd0e1fd",
   "metadata": {},
   "source": [
    "![image.png](image10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26cd8b-cdd2-4f99-b704-6c264a2eb5af",
   "metadata": {},
   "source": [
    "Ne iÅŸe yarÄ±yor?  \n",
    "Bu araÃ§, yazdÄ±ÄŸÄ±nÄ±z metni GPT'nin nasÄ±l gÃ¶rdÃ¼ÄŸÃ¼nÃ¼ gÃ¶sterir. Metninizi token'lara bÃ¶ler ve her token'Ä± farklÄ± renklerle iÅŸaretler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0168a149-7d1b-4ef9-81f0-6e427ce8127a",
   "metadata": {},
   "source": [
    "Neden Ã¶nemli?\n",
    "\n",
    "* Maliyet hesaplama: API kullanÄ±mÄ± token sayÄ±sÄ±na gÃ¶re Ã¼cretlendirilir\n",
    "* Limit kontrolÃ¼: GPT'nin token limiti var (Ã¶rn. 4K, 8K)\n",
    "* Optimizasyon: Daha az token kullanarak aynÄ± anlamÄ± ifade edebilirsiniz\n",
    "\n",
    "KÄ±saca: Bu araÃ§, GPT'nin gÃ¶zÃ¼nden metninizi gÃ¶rmenizi saÄŸlar ve maliyet/limit planlamasÄ± yapmaya yarar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594a1ee-7b8f-4b48-816d-6f837aa604a1",
   "metadata": {},
   "source": [
    "\n",
    "**SayÄ±lar ve Matematik Sorunu:**\n",
    "- \"Ed Donner's fave number is 3.14159265358979...\" cÃ¼mlesi\n",
    "- **17 token, 47 karakter**\n",
    "- Uzun sayÄ±lar birden fazla token'a bÃ¶lÃ¼nÃ¼r\n",
    "- Bu yÃ¼zden erken GPT modelleri matematik iÅŸlemlerinde zorlanÄ±yordu - sayÄ±larÄ± parÃ§a parÃ§a gÃ¶rÃ¼yorlardÄ±!\n",
    "\n",
    "**Ã–nemli Kurallar (Ä°ngilizce iÃ§in):**\n",
    "- **1 token â‰ˆ 4 karakter**\n",
    "- **1 token â‰ˆ 0.75 kelime**\n",
    "- **1,000 token â‰ˆ 750 kelime**\n",
    "\n",
    "**Pratik Ã–rnekler:**\n",
    "- Shakespeare'in tÃ¼m eserleri: ~900,000 kelime = 1.2M token\n",
    "- Matematik, bilimsel terimler ve kod daha fazla token tÃ¼ketir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21b4c69-43e8-406e-8fdd-9e4fde5b4274",
   "metadata": {},
   "source": [
    "![image.png](image11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec053a77-ce9f-442a-a13a-54159bdbfed4",
   "metadata": {},
   "source": [
    "* FarklÄ± tokenizerlar farklÄ± ÅŸekilde Ã§alÄ±ÅŸabilir.  \n",
    "* Daha az jeton veya daha fazla jeton sahibi olmanÄ±n artÄ±larÄ± ve eksileri vardÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c17e5-73c2-4047-bd1f-e40f2cee47b2",
   "metadata": {},
   "source": [
    "## Context Window\n",
    "\n",
    "Context Window, LLM'lerin bir seferde \"hatÄ±rlayabildiÄŸi\" maksimum token sayÄ±sÄ±dÄ±r - yani dijital kÄ±sa sÃ¼reli hafÄ±zasÄ±. Bu pencere iÃ§inde tÃ¼m konuÅŸma geÃ§miÅŸi, promptlar ve Ã§Ä±ktÄ±lar yer alÄ±r.\n",
    "\n",
    "KÄ±sa konuÅŸmalar iÃ§in sorun yaratmaz, ancak uzun dÃ¶kÃ¼manlarÄ± analiz etmek veya Ã§ok Ã¶rnekli prompt'lar hazÄ±rlamak iÃ§in kritik Ã¶nem taÅŸÄ±r. Context window dolduÄŸunda model eski bilgileri \"unutur\" ve sadece en gÃ¼ncel bilgilere odaklanÄ±r.\n",
    "\n",
    "GÃ¶rseldeki vitrin penceresi analojisi durumu gÃ¼zel Ã¶zetliyor - modelin \"gÃ¶rebildiÄŸi\" alan sÄ±nÄ±rlÄ±. GPT-3.5 yaklaÅŸÄ±k 4K token (~3,000 kelime) ile sÄ±nÄ±rlÄ±yken, GPT-4 32K token'a, Claude ise 100K+ token'a kadar Ã§Ä±kabiliyor. Context window bÃ¼yÃ¼dÃ¼kÃ§e modeller daha uzun dÃ¶kÃ¼manlarÄ± analiz edebilir ve tutarlÄ± uzun konuÅŸmalar yapabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f291d-ae15-4c68-aee6-e636025417ff",
   "metadata": {},
   "source": [
    "![](image12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc279ac4-d670-4d92-8a7e-9d7f6fb2c78f",
   "metadata": {},
   "source": [
    "Gemini 1.5 Flash'Ä±n 1,000,000 token'lÄ±k context window'u ÅŸu anlama geliyor:\n",
    "\n",
    "- **Tek bir konuÅŸmada** 1 milyon token'a kadar bilgiyi aynÄ± anda iÅŸleyebilir\n",
    "- Ama bu bilgiyi **konuÅŸma bitince unutur**\n",
    "- Yeni bir konuÅŸma baÅŸladÄ±ÄŸÄ±nda sÄ±fÄ±rdan baÅŸlar\n",
    "\n",
    "**Pratik Ã¶rnek:**\n",
    "- Gemini'ye 800 sayfalÄ±k bir kitap yÃ¼kleyin (yaklaÅŸÄ±k 1M token)\n",
    "- O kitap hakkÄ±nda sorular sorabilirsiniz\n",
    "- KitabÄ±n tamamÄ±nÄ± \"aklÄ±nda\" tutarak cevap verir\n",
    "- Ama konuÅŸma bitince kitabÄ± tamamen unutur\n",
    "  \n",
    "Yani Gemini 1.5 Flash Ã§ok daha bÃ¼yÃ¼k dÃ¶kÃ¼manlarÄ± tek seferde iÅŸleyebilir, ancak bu \"kalÄ±cÄ± hafÄ±za\" deÄŸil, sadece \"anlÄ±k iÅŸleme kapasitesi\". Her yeni konuÅŸma temiz sayfa ile baÅŸlar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29a5eb-af06-410c-b076-aa38c8d1bf2e",
   "metadata": {},
   "source": [
    "**Senaryo:** Gemini 1.5 Flash'a 500 sayfalÄ±k bir rapor yÃ¼kleyip analiz ettiriyorsunuz.\n",
    "\n",
    "**INPUT (GiriÅŸ - $0.35/1M token):**\n",
    "\n",
    "- 500 sayfalÄ±k rapor: ~400,000 token\n",
    "- SorduÄŸunuz soru: \"Bu rapordaki en Ã¶nemli 5 bulguyu listele\" - 100 token\n",
    "- **Toplam input:** 400,100 token\n",
    "- **Input maliyeti:** 400,100 Ã· 1,000,000 Ã— $0.35 = **  $0.14  **\n",
    "\n",
    "**OUTPUT (Ã‡Ä±kÄ±ÅŸ - $0.70/1M token):**\n",
    "\n",
    "- Gemini'nin Ã¼rettiÄŸi cevap: 5 bulgu + aÃ§Ä±klamalar = 800 token\n",
    "- **Output maliyeti:** 800 Ã· 1,000,000 Ã— $0.70 = **$0.0006**\n",
    "\n",
    "**Toplam maliyet:** $0.14 + $0.0006 = **$0.1406**\n",
    "\n",
    "**GÃ¶rÃ¼nen o ki:**\n",
    "\n",
    "- 500 sayfalÄ±k raporu \"okumak\" (input): $0.14\n",
    "\n",
    "- 800 kelimelik cevap \"yazmak\" (output): $0.0006\n",
    "\n",
    "Bu Ã¶rnekte input maliyeti Ã§ok daha yÃ¼ksek Ã§Ã¼nkÃ¼ Ã§ok bÃ¼yÃ¼k bir dÃ¶kÃ¼man yÃ¼klediniz. Ama eÄŸer kÄ±sa bir soru sorup uzun bir makale yazdÄ±rÄ±rsanÄ±z, o zaman output maliyeti daha yÃ¼ksek olur.\n",
    "\n",
    "**Ekonomik kullanÄ±m ipucu:** BÃ¼yÃ¼k dÃ¶kÃ¼manlarÄ± bir kez yÃ¼kleyip birden fazla kÄ±sa soru sormak daha mantÄ±klÄ±!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b128c-793d-434b-8ac5-2238eb7a22f1",
   "metadata": {},
   "source": [
    "--- \n",
    "## 5. GÃ¼n\n",
    "\n",
    "**Zero-Shot Prompting:**\n",
    "Modele hiÃ§bir Ã¶rnek vermeden, sadece gÃ¶revin ne olduÄŸunu aÃ§Ä±klayarak istekte bulunmak.\n",
    "\n",
    "*Ã–rnek:* \"Bu metni Ä°ngilizce'ye Ã§evir: Merhaba, nasÄ±lsÄ±n?\"\n",
    "\n",
    "**One-Shot Prompting:**\n",
    "Modele bir Ã¶rnek verip, aynÄ± formatÄ± takip etmesini istemek.\n",
    "\n",
    "*Ã–rnek:* \n",
    "\"TÃ¼rkÃ§e: Merhaba, nasÄ±lsÄ±n?\n",
    "Ä°ngilizce: Hello, how are you?\n",
    "\n",
    "TÃ¼rkÃ§e: Bu kitap Ã§ok gÃ¼zel.\n",
    "Ä°ngilizce:\"\n",
    "\n",
    "**Multishot** \n",
    "Birden fazla Ã¶rnek verme\n",
    "\n",
    "**Fark:** Zero-shot'ta model sadece talimatÄ± anlamaya Ã§alÄ±ÅŸÄ±r, one-shot'ta hem talimatÄ± hem de Ã¶rnek formatÄ± gÃ¶rÃ¼r. One-shot genellikle daha tutarlÄ± sonuÃ§lar verir Ã§Ã¼nkÃ¼ model tam olarak ne beklediÄŸinizi anlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc78e2-51c1-401e-b001-62dacf1c4e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
