{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "092cbdfb-53ac-4d3a-a18a-4f944af26b30",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![image.png](image01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8715e438-0e5f-4d24-bedc-2c133ee256d6",
   "metadata": {},
   "source": [
    "\n",
    "## 🔠 **LLM (Large Language Model)** nedir?\n",
    "\n",
    "**Çok büyük miktarda metin verisiyle eğitilmiş yapay zeka modelleridir.**\n",
    "Doğal dil üretme, anlama, çeviri, özetleme gibi görevleri yerine getirir.\n",
    "👉 *(Örnek: GPT-4, Claude, LLaMA, Mistral)*\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Models (Modeller)\n",
    "\n",
    "* **Open-Source:** Kaynak kodu açık modeller.\n",
    "  👉 *(Örnek: LLaMA 2, Mistral, Falcon)*\n",
    "* **Closed Source:** Kaynak kodu kapalı, sadece API ile erişilebilen modeller.\n",
    "  👉 *(Örnek: GPT-4, Claude)*\n",
    "* **Multi-modal:** Metin + Görsel + Ses gibi farklı veri türlerini aynı anda işleyebilen modeller.\n",
    "  👉 *(Örnek: GPT-4o, Gemini, Claude 3.5 Sonnet)*\n",
    "* **Architecture:** Modelin katman yapısı, dikkat mekanizmaları, transformer yapısı gibi iç tasarımı.\n",
    "  👉 *(Örnek: Decoder-only, Encoder-decoder transformer)*\n",
    "* **Selecting:** Uygun modeli seçme süreci; kullanım senaryosuna göre doğru LLM’i belirleme.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Tools (Araçlar)\n",
    "\n",
    "* **HuggingFace:** Model paylaşımı, eğitimi ve çalıştırması için popüler bir platform.\n",
    "  👉 *(transformers, datasets gibi paketleri vardır)*\n",
    "* **LangChain:** LLM'leri zincirleme işlemler ve dış kaynaklarla (veritabanı, API) bağlama kütüphanesi.\n",
    "  👉 *(Örnek: veritabanından bilgi al, LLM’e gönder, sonuç üret)*\n",
    "* **Gradio:** Modeller için hızlıca web arayüzü oluşturmayı sağlayan araç.\n",
    "* **Weights & Biases:** Eğitim sürecini görselleştirme ve izleme aracı (ML ops için).\n",
    "* **Modal:** Sunucusuz (serverless) LLM uygulamaları dağıtımı için platform.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Techniques (Teknikler)\n",
    "\n",
    "* **APIs:** Modellerle REST API üzerinden iletişim kurma yöntemi.\n",
    "  👉 *(Örnek: OpenAI API kullanarak cevap alma)*\n",
    "* **Multi-shot prompting:** LLM'e birden fazla örnek vererek daha doğru cevap almayı hedefleme.\n",
    "  👉 *(Örnek: 3 soru-cevap örneği verip 4. cevabı istemek)*\n",
    "* **RAG (Retrieval-Augmented Generation):** LLM'e dış kaynaktan bilgi getirip, o bilgiyle cevap ürettirme.\n",
    "  👉 *(Örnek: Belgeleri tarayıp onlardan özet üretme)*\n",
    "* **Fine-tuning:** Modelin belirli bir görev veya veriyle yeniden eğitilmesi.\n",
    "  👉 *(Örnek: Bir müşteri hizmetleri chatbot'u için GPT'yi ince ayarlamak)*\n",
    "* **Agentization:** LLM'in kendi kararlarını verip adım adım işlem yapabilen \"ajan\" gibi çalışması.\n",
    "  👉 *(Örnek: Bir görevi çözüme ulaştırmak için araç çağırma, plan yapma)*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c2da3c-5323-4dee-b346-d1972e67be16",
   "metadata": {},
   "source": [
    "![image.png](image02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348d91d-25d8-488c-bb11-ad883c4198bd",
   "metadata": {},
   "source": [
    "\n",
    "1. **Chat interfaces (Sohbet Arayüzleri):**\n",
    "\n",
    "   * Örnek: ChatGPT gibi platformlar\n",
    "   * Kullanıcıların doğrudan sohbet ederek modeli kullanmalarını sağlar.\n",
    "\n",
    "2. **Cloud APIs (Bulut API’leri):**\n",
    "\n",
    "   * LLM API’leri üzerinden\n",
    "   * LangChain gibi framework’lerle entegre edilir.\n",
    "   * Yönetilen AI hizmetleri:\n",
    "\n",
    "     * Amazon Bedrock\n",
    "     * Google Vertex\n",
    "     * Azure ML\n",
    "\n",
    "3. **Direct inference (Doğrudan çıkarım):**\n",
    "\n",
    "   * HuggingFace Transformers kütüphanesi ile\n",
    "   * Ollama gibi araçlarla yerel çalıştırma yapılabilir.\n",
    "\n",
    "---\n",
    "### **Yönetilen AI hizmetleri:**\n",
    "\n",
    "Bunlar, büyük bulut sağlayıcılarının sunduğu hazır altyapılardır. Model eğitme, çalıştırma ve ölçekleme işlemlerini senin yerine yaparlar.\n",
    "\n",
    "* **Amazon Bedrock, Google Vertex AI, Azure ML** gibi platformlar buna örnektir.\n",
    "* Kendi donanımın olmadan büyük dil modellerini kullanabilirsin.\n",
    "\n",
    "### **Ollama:**\n",
    "\n",
    "Ollama, dil modellerini **kendi bilgisayarında (lokal)** çalıştırmanı sağlayan bir araçtır.\n",
    "\n",
    "* İnternete gerek kalmadan, örneğin LLaMA gibi modelleri PC’de hızlıca çalıştırabilirsin.\n",
    "* Geliştiriciler için hafif ve kolaydır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e295c1f-80ac-4f5d-9d77-bf104422cbd1",
   "metadata": {},
   "source": [
    "# Frontier AI Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce83136-58b1-44ab-8a1e-0152ece7df39",
   "metadata": {},
   "source": [
    "![image.png](image03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3596da2-678e-4dde-86d1-117e326e4be8",
   "metadata": {},
   "source": [
    "![image.png](image04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791bf26-a222-47e8-9989-487151ccdd49",
   "metadata": {},
   "source": [
    "Frontier LLM’ler artık bilgi sentezi, yazı üretimi ve kodlama gibi konularda insan düzeyine çok yaklaşmış durumda.\n",
    "\n",
    "Bu yüzden insanlar artık Stack Overflow gibi sitelere değil, bu modellere başvuruyor.\n",
    "\n",
    "Yani bu modeller, hem bilgi kaynaklarını değiştiriyor hem de çalışma alışkanlıklarını kökten etkiliyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27309d-61b3-45f3-b4a1-fabe7fdd5c14",
   "metadata": {},
   "source": [
    "![image.png](image05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3b783-299c-4c97-b386-46316f509b3c",
   "metadata": {},
   "source": [
    "## Neden Frontier Modeller basit sorularda yanlış yapar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378a5c5-da96-474a-8bfa-719681330883",
   "metadata": {},
   "source": [
    "Gerçek şu ki, bu bilginin LLM'e gönderilme şekliyle ve tokenizasyon stratejisi ilgili. LLM harfler veya kelimeler nedir bilmez. Token'ları alırlar ve bundan dolayı çoğu zaman büyük matematiksel işlemleri yapamazlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec6ce3-4b52-4bae-a273-db53efacf360",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "* Tüm 6 ileri düzey LLM modeli şaşırtıcı derecede iyi.  \n",
    "Özellikle bilgiyi sentezleme ve ayrıntılı cevaplar üretme konusunda çok başarılılar.\n",
    "\n",
    "* Claude (Anthropic'in LLM'si), pratikte en çok tercih edilen model.  \n",
    "Çünkü daha esprili, güvenliğe daha çok önem veriyor ve daha özlü yanıtlar veriyor.\n",
    "\n",
    "* Modellerin yetenekleri birbirine yaklaştıkça, fiyat fark yaratabilir.  \n",
    "Yeni geliştirmeler, daha ucuz modellere odaklanıyor.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40b6396e-7981-4892-99bf-cadcd256fbd5",
   "metadata": {},
   "source": [
    "![image.png](image06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4b0caf-bc99-4694-a9f7-7f4c1c1bb633",
   "metadata": {},
   "source": [
    "Google'daki çalışanlar \"Attention is All You need\" makalesini yayımladı ve ilk kez transformer modeller burada bahsedildi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6304cf5-7be7-48b2-b2ab-f72774225982",
   "metadata": {},
   "source": [
    "## LLM'in parametreleri:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237a6f9-f452-4ee4-bebf-a6e9e7b08b4c",
   "metadata": {},
   "source": [
    "LLM'lerde parametre sayısı, modelin **öğrenilebilir ağırlık ve bias değerlerinin** toplam sayısını ifade eder.\n",
    "\n",
    "**Parametreler nelerdir?**\n",
    "- **Ağırlıklar (weights)**: Katmanlar arasındaki bağlantıların gücünü belirleyen değerler\n",
    "- **Bias değerleri**: Her nöronun aktivasyon eşiğini ayarlayan değerler\n",
    "- **Embedding matrisleri**: Kelimeleri sayısal vektörlere dönüştüren tablolar\n",
    "- **Attention mekanizması ağırlıkları**: Transformer'larda hangi kelimelere odaklanacağını belirleyen değerler\n",
    "\n",
    "**Neden önemli?**\n",
    "- **Model kapasitesi**: Daha fazla parametre genellikle daha karmaşık kalıpları öğrenebilme yeteneği demek\n",
    "- **Hesaplama maliyeti**: Parametre sayısı arttıkça eğitim ve çalıştırma maliyeti artar\n",
    "- **Bellek gereksinimi**: Her parametre bellekte yer kaplar\n",
    "\n",
    "**Örnekler:**\n",
    "- GPT-3: ~175 milyar parametre\n",
    "- GPT-4: Tam sayı açıklanmadı ama trilyon civarında tahmin ediliyor\n",
    "- BERT Base: ~110 milyon parametre\n",
    "\n",
    "Yani kısaca, parametre sayısı modelin \"beyinindeki sinaps sayısı\" gibi düşünülebilir - ne kadar çok parametre, o kadar karmaşık düşünme yeteneği."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191594a-fb1f-46cb-a0c0-18d7b2ec33df",
   "metadata": {},
   "source": [
    "![image.png](image07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a38c9f2-6d34-4add-b063-f1a3f3b9d80c",
   "metadata": {},
   "source": [
    "![image.png](image08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f74187-e915-4942-b26d-b7e7fc818fee",
   "metadata": {},
   "source": [
    "\n",
    "**Token nedir?**  \n",
    "Token, LLM'lerin metni işlerken kullandığı en küçük anlamlı birimdir. Kelimeden daha küçük, karakterden daha büyük parçalardır.\n",
    "\n",
    "**Görseldekilerin açıklaması:**\n",
    "\n",
    "**1. Karakter seviyesi (sol):**\n",
    "- Her harf ayrı ayrı işlenir\n",
    "- Küçük kelime dağarcığı ama çok fazla adım gerekir\n",
    "- \"Merhaba\" için 7 adım (m-e-r-h-a-b-a)\n",
    "\n",
    "**2. Kelime seviyesi (orta):**\n",
    "- Her kelime bir birim olarak işlenir\n",
    "- Öğrenmesi kolay ama nadir kelimeler sorun yaratır\n",
    "- Kelime dağarcığı çok büyük olur\n",
    "\n",
    "**3. Token seviyesi (sağ) - En ideal çözüm:**\n",
    "- Kelimelerin parçalarına bölünür\n",
    "- Hem yönetilebilir kelime dağarcığı hem de verimli işleme\n",
    "- Ek'leri, kök'leri ayrı ayrı anlayabilir\n",
    "\n",
    "**Örnekler:**\n",
    "- \"oyuncu\" → [\"oyun\", \"cu\"]\n",
    "- \"koşuyorum\" → [\"koş\", \"uyor\", \"um\"]\n",
    "- \"AI\" → [\"A\", \"I\"] (kısa olduğu için bölünmez)\n",
    "\n",
    "**Neden önemli?**\n",
    "- Farklı dillerdeki ekleri anlayabilir\n",
    "- Yeni kelimeler görse bile kök ve eklerden anlam çıkarabilir\n",
    "- Bellek kullanımı optimize edilir\n",
    "\n",
    "Token'lar sayesinde LLM'ler hem verimli hem de esnek bir şekilde dil işleyebilirler!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4910791-e9a4-42d7-b550-799009e6551d",
   "metadata": {},
   "source": [
    "![image.png](image09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df01ec-2a87-43ae-be84-763e6dd0e1fd",
   "metadata": {},
   "source": [
    "![image.png](image10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26cd8b-cdd2-4f99-b704-6c264a2eb5af",
   "metadata": {},
   "source": [
    "Ne işe yarıyor?  \n",
    "Bu araç, yazdığınız metni GPT'nin nasıl gördüğünü gösterir. Metninizi token'lara böler ve her token'ı farklı renklerle işaretler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0168a149-7d1b-4ef9-81f0-6e427ce8127a",
   "metadata": {},
   "source": [
    "Neden önemli?\n",
    "\n",
    "* Maliyet hesaplama: API kullanımı token sayısına göre ücretlendirilir\n",
    "* Limit kontrolü: GPT'nin token limiti var (örn. 4K, 8K)\n",
    "* Optimizasyon: Daha az token kullanarak aynı anlamı ifade edebilirsiniz\n",
    "\n",
    "Kısaca: Bu araç, GPT'nin gözünden metninizi görmenizi sağlar ve maliyet/limit planlaması yapmaya yarar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594a1ee-7b8f-4b48-816d-6f837aa604a1",
   "metadata": {},
   "source": [
    "\n",
    "**Sayılar ve Matematik Sorunu:**\n",
    "- \"Ed Donner's fave number is 3.14159265358979...\" cümlesi\n",
    "- **17 token, 47 karakter**\n",
    "- Uzun sayılar birden fazla token'a bölünür\n",
    "- Bu yüzden erken GPT modelleri matematik işlemlerinde zorlanıyordu - sayıları parça parça görüyorlardı!\n",
    "\n",
    "**Önemli Kurallar (İngilizce için):**\n",
    "- **1 token ≈ 4 karakter**\n",
    "- **1 token ≈ 0.75 kelime**\n",
    "- **1,000 token ≈ 750 kelime**\n",
    "\n",
    "**Pratik Örnekler:**\n",
    "- Shakespeare'in tüm eserleri: ~900,000 kelime = 1.2M token\n",
    "- Matematik, bilimsel terimler ve kod daha fazla token tüketir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21b4c69-43e8-406e-8fdd-9e4fde5b4274",
   "metadata": {},
   "source": [
    "![image.png](image11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec053a77-ce9f-442a-a13a-54159bdbfed4",
   "metadata": {},
   "source": [
    "* Farklı tokenizerlar farklı şekilde çalışabilir.  \n",
    "* Daha az jeton veya daha fazla jeton sahibi olmanın artıları ve eksileri vardır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c17e5-73c2-4047-bd1f-e40f2cee47b2",
   "metadata": {},
   "source": [
    "## Context Window\n",
    "\n",
    "Context Window, LLM'lerin bir seferde \"hatırlayabildiği\" maksimum token sayısıdır - yani dijital kısa süreli hafızası. Bu pencere içinde tüm konuşma geçmişi, promptlar ve çıktılar yer alır.\n",
    "\n",
    "Kısa konuşmalar için sorun yaratmaz, ancak uzun dökümanları analiz etmek veya çok örnekli prompt'lar hazırlamak için kritik önem taşır. Context window dolduğunda model eski bilgileri \"unutur\" ve sadece en güncel bilgilere odaklanır.\n",
    "\n",
    "Görseldeki vitrin penceresi analojisi durumu güzel özetliyor - modelin \"görebildiği\" alan sınırlı. GPT-3.5 yaklaşık 4K token (~3,000 kelime) ile sınırlıyken, GPT-4 32K token'a, Claude ise 100K+ token'a kadar çıkabiliyor. Context window büyüdükçe modeller daha uzun dökümanları analiz edebilir ve tutarlı uzun konuşmalar yapabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f291d-ae15-4c68-aee6-e636025417ff",
   "metadata": {},
   "source": [
    "![](image12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc279ac4-d670-4d92-8a7e-9d7f6fb2c78f",
   "metadata": {},
   "source": [
    "Gemini 1.5 Flash'ın 1,000,000 token'lık context window'u şu anlama geliyor:\n",
    "\n",
    "- **Tek bir konuşmada** 1 milyon token'a kadar bilgiyi aynı anda işleyebilir\n",
    "- Ama bu bilgiyi **konuşma bitince unutur**\n",
    "- Yeni bir konuşma başladığında sıfırdan başlar\n",
    "\n",
    "**Pratik örnek:**\n",
    "- Gemini'ye 800 sayfalık bir kitap yükleyin (yaklaşık 1M token)\n",
    "- O kitap hakkında sorular sorabilirsiniz\n",
    "- Kitabın tamamını \"aklında\" tutarak cevap verir\n",
    "- Ama konuşma bitince kitabı tamamen unutur\n",
    "  \n",
    "Yani Gemini 1.5 Flash çok daha büyük dökümanları tek seferde işleyebilir, ancak bu \"kalıcı hafıza\" değil, sadece \"anlık işleme kapasitesi\". Her yeni konuşma temiz sayfa ile başlar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29a5eb-af06-410c-b076-aa38c8d1bf2e",
   "metadata": {},
   "source": [
    "**Senaryo:** Gemini 1.5 Flash'a 500 sayfalık bir rapor yükleyip analiz ettiriyorsunuz.\n",
    "\n",
    "**INPUT (Giriş - $0.35/1M token):**\n",
    "\n",
    "- 500 sayfalık rapor: ~400,000 token\n",
    "- Sorduğunuz soru: \"Bu rapordaki en önemli 5 bulguyu listele\" - 100 token\n",
    "- **Toplam input:** 400,100 token\n",
    "- **Input maliyeti:** 400,100 ÷ 1,000,000 × $0.35 = **  $0.14  **\n",
    "\n",
    "**OUTPUT (Çıkış - $0.70/1M token):**\n",
    "\n",
    "- Gemini'nin ürettiği cevap: 5 bulgu + açıklamalar = 800 token\n",
    "- **Output maliyeti:** 800 ÷ 1,000,000 × $0.70 = **$0.0006**\n",
    "\n",
    "**Toplam maliyet:** $0.14 + $0.0006 = **$0.1406**\n",
    "\n",
    "**Görünen o ki:**\n",
    "\n",
    "- 500 sayfalık raporu \"okumak\" (input): $0.14\n",
    "\n",
    "- 800 kelimelik cevap \"yazmak\" (output): $0.0006\n",
    "\n",
    "Bu örnekte input maliyeti çok daha yüksek çünkü çok büyük bir döküman yüklediniz. Ama eğer kısa bir soru sorup uzun bir makale yazdırırsanız, o zaman output maliyeti daha yüksek olur.\n",
    "\n",
    "**Ekonomik kullanım ipucu:** Büyük dökümanları bir kez yükleyip birden fazla kısa soru sormak daha mantıklı!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b128c-793d-434b-8ac5-2238eb7a22f1",
   "metadata": {},
   "source": [
    "--- \n",
    "## 5. Gün\n",
    "\n",
    "**Zero-Shot Prompting:**\n",
    "Modele hiçbir örnek vermeden, sadece görevin ne olduğunu açıklayarak istekte bulunmak.\n",
    "\n",
    "*Örnek:* \"Bu metni İngilizce'ye çevir: Merhaba, nasılsın?\"\n",
    "\n",
    "**One-Shot Prompting:**\n",
    "Modele bir örnek verip, aynı formatı takip etmesini istemek.\n",
    "\n",
    "*Örnek:* \n",
    "\"Türkçe: Merhaba, nasılsın?\n",
    "İngilizce: Hello, how are you?\n",
    "\n",
    "Türkçe: Bu kitap çok güzel.\n",
    "İngilizce:\"\n",
    "\n",
    "**Multishot** \n",
    "Birden fazla örnek verme\n",
    "\n",
    "**Fark:** Zero-shot'ta model sadece talimatı anlamaya çalışır, one-shot'ta hem talimatı hem de örnek formatı görür. One-shot genellikle daha tutarlı sonuçlar verir çünkü model tam olarak ne beklediğinizi anlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc78e2-51c1-401e-b001-62dacf1c4e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
